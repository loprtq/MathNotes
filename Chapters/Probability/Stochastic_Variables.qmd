::: {.hidden}
$$
\newcommand{\Pr}[1]{\mathbb{P}\left(#1\right)}
\newcommand{\E}[1]{\mathbb{E}\left[#1\right]}
\newcommand{\Var}[1]{\operatorname{Var}\left[#1\right]}
\newcommand{\Cov}[1]{\operatorname{Cov}\left[#1\right]}
\newcommand{\Cor}[1]{\operatorname{Cor}\left[#1\right]}
$$
:::

# Stochastic Variables {#sec-Stochastic_Variables}
Stochastistic variables are functions $X: \Omega \to \mathcal{E}$, where $\mathcal{E}$ is typically a countable space for discrete stochastic variables and $\mathbb{R}$ for continuous stochastic variables.

## Probability mass function (PMF) {#sec-PMF}
The probability mass function describes the probability of a discrete stochastic variable $X$ being equal to $x$. Think back to the example of a six sided die, where the probability of each side is $1/6$, then the PMF would be constant.
$$
p_X(x) = \Pr{X = x}
$$
where $\sum_{x} p_X\left(x\right) = 1$.

## Cumulative distribution function (CDF) {#sec-CDF}
The cumulative distribution function describes the probability of a stochastic variable being less than or equal to $x$ - the probability that some $x$ is larger than the stochastic variable $X$:
$$
F_X(x) = \Pr{X \leq x}.
$$
The phrasing of the CDF might sound familiar if you have previously worked with p-values (see @sec-p_values).

The median of a stochastic variable is the $x_m$ where $F_X\left(x_m\right) = 0.5$.

monotone decreasing and right-continuous.

## Probability density function (PDF) {#sec-PDF}
The probability density function is an extension to the PMF for continuous stochastic variables.
$$
f_X(x) = \frac{\partial}{\partial x} F_X(x)
$$
where $\int_0^\infty f_x(x)\,\mathrm{d}x = 1$ - the area under the curve is exactly 1.

## Expected Value {#sec-Expected_Value}
The expected value of a stochastic variable, is often referred to as the mean of the stochastic variable. This is easier to see for discrete stochastic variables in the following.
$$
\begin{aligned}
    \E{X} &= \begin{cases}
        \sum_{k = 1}^\infty x_k \cdot p_X\left(x_k\right) & X\textrm{ is a discrete stochastic variable}\\
        \int_{-\infty}^\infty x \cdot f_X\left(x\right) & X\textrm{ is a continous stochastic variable}\end{cases}
\end{aligned}
$$ {#eq-Expected_Value}

For a series of stochastic variables $X_1, X_2,\dots, X_n$, the sum of the expected values is the same as the expected value of the sum of stochastic variables - $\sum_{i=1}^n\E{X_i} = \E{\sum_{i=1}^n X_i}$.

If the two stochastic variables $X$ and $Y$ are independent, then $\E{X \cdot Y} = \E{X} \cdot \E{Y}$.

### Conditional Expected Value {#sec-Cond_Expected_Value}
$$
\begin{aligned}
    \E{X} &= \begin{cases}1\\2\end{cases}
\end{aligned}
$$

$$
\E{X} = \E{\E{Y\mid X}}
$$

## Variance {#sec-Variance}
$$
\begin{aligned}
    \Var{X} &= \E{\left(X - \E{X}\right)^2}\\
    &= \E{X^2} - \left(\E{X}\right)^2
\end{aligned}
$$
where $\Var{X} \geq 0$.

$\Var{a \cdot X + b} = a^2 \cdot \Var{X}$, because $\Var{b} = 0$.

The standard deviation of the stochastic variable is $\sqrt{\Var{X}}$. The standard deviation can be thought of as what the 

### Covariance {#sec-Covariance}
$$
\begin{aligned}
    \Cov{X, Y} &= \E{X \cdot Y} - \E{X}\E{Y}\\
    &= \E{\left(X - \E{X}\right)\left(Y - \E{Y}\right)}
\end{aligned}
$$ {#eq-Covariance}

If the two stochastic variables $X$ and $Y$ are independent, then their covariance is 0. However, the converse is not true - even though the covariance between two stochastic variables is 0, then they are not independent.

The covariance between a stochastic variable and itself is equivalent to the stochastic variable's variance - $\Cov{X,X} = \Var{X}$.

$\Cov{a \cdot X + b, c \cdot Y + d} = a \cdot c \cdot \Cov{X, Y}$.

$\Var{X + Y} = \Var{X} + \Var{Y} + 2 \cdot \Cov{X, Y}$.

### Correlation {#sec-Correlation}
$$
\Cor{X, Y} = \frac{\Cov{X, Y}}{\sqrt{\Var{X} \Var{Y}}}
$$ {eq-Correlation}
Similiar to how the covariance is 0 for independent variables, this is also the case for the correlation. However, even if two stochastic variables are uncorrelated (their correlation is 0), they are not neccesarily independent.